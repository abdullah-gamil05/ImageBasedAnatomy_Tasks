{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1742906,"sourceType":"datasetVersion","datasetId":1034643},{"sourceId":2527926,"sourceType":"datasetVersion","datasetId":1531638},{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934},{"sourceId":2999507,"sourceType":"datasetVersion","datasetId":1837618},{"sourceId":4576891,"sourceType":"datasetVersion","datasetId":2669957},{"sourceId":9744330,"sourceType":"datasetVersion","datasetId":5965032},{"sourceId":9747392,"sourceType":"datasetVersion","datasetId":5967359},{"sourceId":9747414,"sourceType":"datasetVersion","datasetId":5967377},{"sourceId":9747426,"sourceType":"datasetVersion","datasetId":5967387},{"sourceId":9747483,"sourceType":"datasetVersion","datasetId":5967437},{"sourceId":9747651,"sourceType":"datasetVersion","datasetId":5967539},{"sourceId":9747697,"sourceType":"datasetVersion","datasetId":5967578}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Import necessary libraries\nimport os\nimport shutil\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\nfrom tensorflow.keras.applications import VGG16\nimport matplotlib.pyplot as plt\n\n# step2: Set source directories for each organ\nsource_dirs = {\n    'brain': '/kaggle/input/brain-tumor-mri-dataset',\n    'breast': '/kaggle/input/breast-cancer-patients-mris',\n    'liver': '/kaggle/input/liver-dataset',\n    'lung': '/kaggle/input/cardiomegaly-disease-prediction-using-cnn'\n}\n\n#step3:create Base directory to store organized dataset\nbase_dir = '/kaggle/working/organized_dataset'\ntrain_dir = os.path.join(base_dir, 'train')\nval_dir = os.path.join(base_dir, 'validation')\ntest_dir = os.path.join(base_dir, 'test')\n\n#step4: Ensure destination directories exist\nfor organ in source_dirs.keys():\n    os.makedirs(os.path.join(train_dir, organ), exist_ok=True)\n    os.makedirs(os.path.join(val_dir, organ), exist_ok=True)\n    os.makedirs(os.path.join(test_dir, organ), exist_ok=True)\n\n#step5: Define Supported image extensions\nsupported_extensions = ('.jpg', '.jpeg', '.png')\n\n#step6: Dfine Helper function to retrieve all image paths in nested directories\ndef get_image_paths(root_dir):\n    image_paths = []\n    for root, dirs, files in os.walk(root_dir):\n        for file in files:\n            if file.lower().endswith(supported_extensions):\n                image_paths.append(os.path.join(root, file))\n    return image_paths\n\n#step7: Split and copy files to organized directories\nfor organ, paths in source_dirs.items():\n    if os.path.exists(paths):\n        images = get_image_paths(paths)\n    else:\n        print(f\"Path does not exist: {paths}\")\n        continue\n\n    print(f\"Found {len(images)} images for organ '{organ}'.\")\n\n    if len(images) == 0:\n        print(f\"No images found for organ: {organ}\")\n        continue\n\n    # Split images into 80% train, 10% validation, 10% test\n    train_imgs, temp_imgs = train_test_split(images, test_size=0.2, random_state=42)\n    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n\n    # Copy images to train, validation, and test directories\n    for img_path in train_imgs:\n        shutil.copy(img_path, os.path.join(train_dir, organ, os.path.basename(img_path)))\n\n    for img_path in val_imgs:\n        shutil.copy(img_path, os.path.join(val_dir, organ, os.path.basename(img_path)))\n\n    for img_path in test_imgs:\n        shutil.copy(img_path, os.path.join(test_dir, organ, os.path.basename(img_path)))\n\nprint(\"Dataset organized successfully.\")\n\n# Step 8: Define model parameters\nbatch_size = 32\nepochs = 20  # Increased to improve training\n\n# Step 9: Initialize ImageDataGenerator with augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,  # Small rotation\n    width_shift_range=0.1,  # Slight horizontal shift\n    height_shift_range=0.1, # Slight vertical shift\n    zoom_range=0.1,         # Slight zoom\n    validation_split=0.1    # Keep this for validation split\n)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Step 10: Load training and validation data\ntrain_data = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='grayscale',  \n    subset='training',\n    shuffle=True\n)\n\nvalidation_data = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='grayscale',  \n    subset='validation',\n    shuffle=False\n)\n\n# Load testing data\ntest_data = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(128, 128),\n    batch_size=batch_size,\n    class_mode='categorical',\n    color_mode='grayscale',  \n    shuffle=False\n)\n\n# Step 11: Build the model using Transfer Learning (VGG16)\nbase_model = VGG16(input_shape=(128, 128, 3), include_top=False, weights='/kaggle/input/vgg16-dataset/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')  # Update this path\nbase_model.trainable = False  # Freeze VGG16 layers\n\nmodel = Sequential([\n    Input(shape=(128, 128, 1)),  # Keep the input shape for grayscale\n    Conv2D(3, (1, 1), activation='relu'),  # Adapt grayscale to RGB channels\n    base_model,\n    Flatten(),\n    Dense(128, activation='relu'),          # Increased dense layer size\n    Dense(len(source_dirs), activation='softmax')\n])\n\n\n# Step 12: Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Step 13: Calculate steps per epoch\nsteps_per_epoch = train_data.samples // batch_size\nvalidation_steps = validation_data.samples // batch_size\ntest_steps = test_data.samples // batch_size\n\n# Step 14: Train the model\nhistory = model.fit(\n    train_data,\n    validation_data=validation_data,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps\n)\n\n# Step 15: Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(test_data, steps=test_steps)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Loss: {test_loss:.4f}\")\n\n# Step 16: Plot training & validation accuracy and loss\nplt.figure(figsize=(12, 5))\n\n# Plot accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='upper left')\nplt.grid()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper left')\nplt.grid()\n\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the trained model with a custom name\nmodel_path = '/kaggle/working/team12_model.h5'  \nmodel.save(model_path)\n\nprint(f\"Model saved successfully at: {model_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:37:04.614749Z","iopub.execute_input":"2024-10-28T19:37:04.615244Z","iopub.status.idle":"2024-10-28T19:37:04.775418Z","shell.execute_reply.started":"2024-10-28T19:37:04.615199Z","shell.execute_reply":"2024-10-28T19:37:04.774103Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model saved successfully at: /kaggle/working/team12_model.h5\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"model.save('/kaggle/working/team12_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:32:14.762777Z","iopub.execute_input":"2024-10-28T20:32:14.763222Z","iopub.status.idle":"2024-10-28T20:32:14.982398Z","shell.execute_reply.started":"2024-10-28T20:32:14.763180Z","shell.execute_reply":"2024-10-28T20:32:14.980653Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"##testing part \n\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Step 11: Testing Code with Confidence Threshold\n# Load and preprocess the test image\ntest_image_path = \"/kaggle/input/liver-test2/WhatsApp Image 2024-10-28 at 22.05.15_7406f608.jpg\"\n\n# Load the image, convert to grayscale, and resize to the model's input size\ntest_image = load_img(test_image_path, color_mode='grayscale', target_size=(128, 128))\ntest_image = img_to_array(test_image)  # Convert to array\ntest_image = test_image / 255.0  # Normalize the image\ntest_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n\n# Make a prediction\npredictions = model.predict(test_image)\n\n# Define a confidence threshold\nconfidence_threshold = 0.5  # Adjust this value based on your needs\n\n# Output the predicted class\npredicted_class = np.argmax(predictions, axis=1)\npredicted_confidence = np.max(predictions, axis=1)\n\n# Map the predicted class index to the organ name\nclass_indices = train_data.class_indices  # Get the class indices from the training data\norgan_labels = {v: k for k, v in class_indices.items()}  # Reverse the mapping\n\nif predicted_confidence[0] < confidence_threshold:\n    print(\"Predicted Organ: Unknown\")\nelse:\n    predicted_organ = organ_labels[predicted_class[0]]  # Get the predicted organ name\n    print(f\"Predicted Organ: {predicted_organ} (Confidence: {predicted_confidence[0]:.2f})\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T19:14:53.960429Z","iopub.execute_input":"2024-10-28T19:14:53.960957Z","iopub.status.idle":"2024-10-28T19:14:54.165617Z","shell.execute_reply.started":"2024-10-28T19:14:53.960911Z","shell.execute_reply":"2024-10-28T19:14:54.164300Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\nPredicted Organ: liver (Confidence: 0.99)\n","output_type":"stream"}],"execution_count":21}]}